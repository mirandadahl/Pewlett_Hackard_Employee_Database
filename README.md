# Pewlett_Hackard_Employee_Database_SQL

## Overview:

This project is focused on the employee data from the 1980s and 1990 with the objective to design tables, import data from six CSV files into a SQL database, and perform data analysis.

## Project Structure:

### 1. Data Modeling:
- Inspected six CSV files to understand the relationships between different entities.
- Created an Entity Relationship Diagram (ERD) using QuickDBD to visualize table relationships.

### 2. Data Engineering:
- Developed table schemas for each CSV file, specifying data types, primary keys, foreign keys, and constraints.
- Ensured correct order of table creation to handle foreign keys.
- Imported CSV data into corresponding SQL tables.

### 3. Data Analysis:
Executed a series of SQL queries to derive meaningful insights from the data, including employee details, hiring information, department managers, and frequency counts of last names.

## Repository Structure:

The project is organized within the 'sql-challenge' repository, featuring a 'EmployeeSQL' and 'SQL' directory. 'EmployeeSQL' contains all CSV files. The 'SQL' directory contains subdirectories for each project phase, including 'DataModeling,' 'DataEngineering,' and 'DataAnalysis.'

## Usage:

- The 'DataModeling' folder includes the ERD diagram or table schemas created for the project.
- The 'DataEngineering' folder houses SQL scripts for creating tables and importing data.
- The 'DataAnalysis' folder contains SQL scripts answering specific questions about the employee data.

## How to Use:

1. Clone the 'sql-challenge' repository.
2. Navigate to the respective directories for data modeling, engineering, and analysis to access relevant scripts and documentation.

## Credits:

This project was completed as part of a data engineering challenge for the Data Visualization and Analytics Boot Camp hosted by the University of Minnesota and is fictional, based on the requirements provided.


